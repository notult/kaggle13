{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84896,"databundleVersionId":10305135,"sourceType":"competition"}],"dockerImageVersionId":30804,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T03:55:37.308827Z","iopub.execute_input":"2024-12-13T03:55:37.309348Z","iopub.status.idle":"2024-12-13T03:55:38.506396Z","shell.execute_reply.started":"2024-12-13T03:55:37.309294Z","shell.execute_reply":"2024-12-13T03:55:38.505120Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s4e12/sample_submission.csv\n/kaggle/input/playground-series-s4e12/train.csv\n/kaggle/input/playground-series-s4e12/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"train_data=pd.read_csv('/kaggle/input/playground-series-s4e12/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T03:55:49.456596Z","iopub.execute_input":"2024-12-13T03:55:49.457006Z","iopub.status.idle":"2024-12-13T03:55:55.708732Z","shell.execute_reply.started":"2024-12-13T03:55:49.456968Z","shell.execute_reply":"2024-12-13T03:55:55.707584Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Feature engineering implementation\n\n# 1. Import necessary libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom catboost import CatBoostRegressor, Pool\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.cluster import KMeans\nfrom datetime import datetime\n\n# Copy the dataset\ndata = train_data.copy()\n\n# 2. Create new features\n\n# (1) Annual income per dependent\n# Calculate the annual income divided by the number of dependents to get the income per dependent.\ndata['Income_per_Dependent'] = data['Annual Income'] / (data['Number of Dependents'] + 1)\n\n# (2) Income categories\n# Categorize annual income into Low (< 30000), Medium (30000-60000), and High (>60000).\ndata['Income_Category'] = pd.cut(data['Annual Income'], bins=[0, 30000, 60000, np.inf], labels=['Low', 'Medium', 'High'])\n\n# (3) Health score per age\n# Standardize the health score by age to evaluate health relative to age.\ndata['Health_per_Age'] = data['Health Score'] / data['Age']\n\n# (4) Family type based on marital status and number of dependents\n# Combine marital status and the number of dependents to create a family type category.\ndata['Family_Type'] = data['Marital Status'] + \"_\" + data['Number of Dependents'].fillna(0).astype(int).astype(str)\n\n# (5) Insurance duration categories\n# Group insurance duration into three categories: Short (0-3), Medium (3-7), and Long (>7).\ndata['Insurance_Duration_Category'] = pd.cut(data['Insurance Duration'], bins=[0, 3, 7, np.inf], labels=['Short', 'Medium', 'Long'])\n\n# (6) Lifestyle index combining exercise frequency and smoking status\n# Combine exercise frequency and smoking status into a lifestyle index.\ndata['Lifestyle_Index'] = data['Exercise Frequency'].map({'Rarely': 1, 'Monthly': 2, 'Daily': 3}) * (data['Smoking Status'] == 'No').astype(int)\n\n# (7) Regional indicators (one-hot encoding for location)\n# Create dummy variables for location to encode regional information.\ndata = pd.get_dummies(data, columns=['Location'], prefix='Location')\n\n# (8) Extract time of policy start from 'Policy Start Date'\n# Extract the hour from the policy start date to analyze contract timing.\ndef extract_hour(date_str):\n    try:\n        # Extract the hour from datetime string\n        return int(date_str.split(' ')[1].split(':')[0])\n    except (IndexError, ValueError):\n        # Return a default value (e.g., -1) for invalid formats\n        return -1\n\n# Apply the function to extract hour\ndata['Policy_Hour'] = data['Policy Start Date'].apply(extract_hour)\n\n# (9) Customer grouping using PCA and clustering\n# Select numeric columns and scale them\nnumeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(data[numeric_cols].fillna(0))\n\n# K-means clustering\n# Apply K-means clustering to group customers into five clusters.\nkmeans = KMeans(n_clusters=5, random_state=42)\ndata['Customer_Group'] = kmeans.fit_predict(scaled_data)\n\n# (10) Interaction terms for health and exercise\n# Create interaction terms to evaluate the combined effect of health and exercise.\ndata['Health_Exercise_Interaction'] = data['Health Score'] * data['Exercise Frequency'].map({'Rarely': 1, 'Monthly': 2, 'Daily': 3})\n\n# 3. Prepare data for CatBoost\n# Define the target variable and features\ndata = data.dropna(subset=['Premium Amount'])  # Drop rows where target is missing\nX = data.drop(columns=['id', 'Premium Amount', 'Policy Start Date'])  # Exclude unnecessary columns\ny = data['Premium Amount']\n\n# Handle missing values in categorical features by replacing NaN with 'Unknown'\nfor col in X.select_dtypes(include=['object']).columns:\n    X[col] = X[col].fillna('Unknown')\n\n# Ensure all categorical columns are strings and properly encoded for CatBoost\nfor col in X.select_dtypes(include=['category', 'object']).columns:\n    X[col] = X[col].astype(str)\n\n# Identify categorical features for CatBoost\ncategorical_features = [col for col in X.columns if X[col].dtype == 'object']\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create CatBoost Pool objects\ntrain_pool = Pool(X_train, y_train, cat_features=categorical_features)\ntest_pool = Pool(X_test, y_test, cat_features=categorical_features)\n\n# 4. Train CatBoost Regressor\ncatboost_model = CatBoostRegressor(\n    iterations=1000,\n    learning_rate=0.05,\n    depth=6,\n    loss_function='RMSE',\n    random_seed=42,\n    verbose=100\n)\n\ncatboost_model.fit(train_pool)\n\n# 5. Evaluate the model using RMSLE\ny_pred = catboost_model.predict(test_pool)\nrmsle = np.sqrt(mean_squared_log_error(y_test, y_pred))\nprint(f\"RMSLE: {rmsle}\")\n\n# Save feature importance\nfeature_importances = catboost_model.get_feature_importance()\nimportant_features = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\nimportant_features.sort_values(by='Importance', ascending=False, inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T03:56:35.676100Z","iopub.execute_input":"2024-12-13T03:56:35.676514Z","iopub.status.idle":"2024-12-13T03:59:34.031241Z","shell.execute_reply.started":"2024-12-13T03:56:35.676474Z","shell.execute_reply":"2024-12-13T03:59:34.029777Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"0:\tlearn: 863.8426139\ttotal: 966ms\tremaining: 16m 5s\n100:\tlearn: 845.4080936\ttotal: 1m 24s\tremaining: 12m 28s\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 108\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# 4. Train CatBoost Regressor\u001b[39;00m\n\u001b[1;32m     99\u001b[0m catboost_model \u001b[38;5;241m=\u001b[39m CatBoostRegressor(\n\u001b[1;32m    100\u001b[0m     iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m    101\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m    106\u001b[0m )\n\u001b[0;32m--> 108\u001b[0m \u001b[43mcatboost_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# 5. Evaluate the model using RMSLE\u001b[39;00m\n\u001b[1;32m    111\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m catboost_model\u001b[38;5;241m.\u001b[39mpredict(test_pool)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/catboost/core.py:5873\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   5872\u001b[0m     CatBoostRegressor\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 5873\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5874\u001b[0m \u001b[43m                 \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5875\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5876\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/catboost/core.py:2410\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2407\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2409\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2410\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2418\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2419\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/catboost/core.py:1790\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1790\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n","File \u001b[0;32m_catboost.pyx:5017\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m_catboost.pyx:5066\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"important_features.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T03:59:43.546365Z","iopub.execute_input":"2024-12-13T03:59:43.546788Z","iopub.status.idle":"2024-12-13T03:59:43.571147Z","shell.execute_reply.started":"2024-12-13T03:59:43.546746Z","shell.execute_reply":"2024-12-13T03:59:43.569677Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mimportant_features\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'important_features' is not defined"],"ename":"NameError","evalue":"name 'important_features' is not defined","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"test=pd.read_csv('/kaggle/input/playground-series-s4e12/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T04:00:07.173709Z","iopub.execute_input":"2024-12-13T04:00:07.174701Z","iopub.status.idle":"2024-12-13T04:00:09.976308Z","shell.execute_reply.started":"2024-12-13T04:00:07.174656Z","shell.execute_reply":"2024-12-13T04:00:09.975175Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"test.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T04:00:03.920028Z","iopub.execute_input":"2024-12-13T04:00:03.921060Z","iopub.status.idle":"2024-12-13T04:00:04.400376Z","shell.execute_reply.started":"2024-12-13T04:00:03.921020Z","shell.execute_reply":"2024-12-13T04:00:04.399324Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 800000 entries, 0 to 799999\nData columns (total 20 columns):\n #   Column                Non-Null Count   Dtype  \n---  ------                --------------   -----  \n 0   id                    800000 non-null  int64  \n 1   Age                   787511 non-null  float64\n 2   Gender                800000 non-null  object \n 3   Annual Income         770140 non-null  float64\n 4   Marital Status        787664 non-null  object \n 5   Number of Dependents  726870 non-null  float64\n 6   Education Level       800000 non-null  object \n 7   Occupation            560875 non-null  object \n 8   Health Score          750551 non-null  float64\n 9   Location              800000 non-null  object \n 10  Policy Type           800000 non-null  object \n 11  Previous Claims       557198 non-null  float64\n 12  Vehicle Age           799997 non-null  float64\n 13  Credit Score          708549 non-null  float64\n 14  Insurance Duration    799998 non-null  float64\n 15  Policy Start Date     800000 non-null  object \n 16  Customer Feedback     747724 non-null  object \n 17  Smoking Status        800000 non-null  object \n 18  Exercise Frequency    800000 non-null  object \n 19  Property Type         800000 non-null  object \ndtypes: float64(8), int64(1), object(11)\nmemory usage: 122.1+ MB\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# (1) Annual income per dependent\n# Calculate the annual income divided by the number of dependents to get the income per dependent.\ntest['Income_per_Dependent'] = test['Annual Income'] / (test['Number of Dependents'] + 1)\n\n# (2) Income categories\n# Categorize annual income into Low (< 30000), Medium (30000-60000), and High (>60000).\ntest['Income_Category'] = pd.cut(test['Annual Income'], bins=[0, 30000, 60000, np.inf], labels=['Low', 'Medium', 'High'])\n\n# (3) Health score per age\n# Standardize the health score by age to evaluate health relative to age.\ntest['Health_per_Age'] = test['Health Score'] / test['Age']\n\n# (4) Family type based on marital status and number of dependents\n# Combine marital status and the number of dependents to create a family type category.\ntest['Family_Type'] = test['Marital Status'] + \"_\" + test['Number of Dependents'].fillna(0).astype(int).astype(str)\n\n# (5) Insurance duration categories\n# Group insurance duration into three categories: Short (0-3), Medium (3-7), and Long (>7).\ntest['Insurance_Duration_Category'] = pd.cut(test['Insurance Duration'], bins=[0, 3, 7, np.inf], labels=['Short', 'Medium', 'Long'])\n\n# (6) Lifestyle index combining exercise frequency and smoking status\n# Combine exercise frequency and smoking status into a lifestyle index.\ntest['Lifestyle_Index'] = test['Exercise Frequency'].map({'Rarely': 1, 'Monthly': 2, 'Daily': 3}) * (test['Smoking Status'] == 'No').astype(int)\n\n# (7) Regional indicators (one-hot encoding for location)\n# Create dummy variables for location to encode regional information.\ntest = pd.get_dummies(test, columns=['Location'], prefix='Location')\n\n# (8) Extract time of policy start from 'Policy Start Date'\n# Extract the hour from the policy start date to analyze contract timing.\ndef extract_hour(date_str):\n    try:\n        # Extract the hour from datetime string\n        return int(date_str.split(' ')[1].split(':')[0])\n    except (IndexError, ValueError):\n        # Return a default value (e.g., -1) for invalid formats\n        return -1\n\n# Apply the function to extract hour\ntest['Policy_Hour'] = test['Policy Start Date'].apply(extract_hour)\n\n# (9) Customer grouping using PCA and clustering\n# Select numeric columns and scale them\nnumeric_cols = test.select_dtypes(include=['float64', 'int64']).columns\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(test[numeric_cols].fillna(0))  # Correctly reference the data using test[numeric_cols]\n\n# K-means clustering\n# Apply K-means clustering to group customers into five clusters.\nkmeans = KMeans(n_clusters=5, random_state=42)\ntest['Customer_Group'] = kmeans.fit_predict(scaled_data)\n\n# (10) Interaction terms for health and exercise\n# Create interaction terms to evaluate the combined effect of health and exercise.\ntest['Health_Exercise_Interaction'] = test['Health Score'] * test['Exercise Frequency'].map({'Rarely': 1, 'Monthly': 2, 'Daily': 3})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T04:01:12.382934Z","iopub.execute_input":"2024-12-13T04:01:12.383320Z","iopub.status.idle":"2024-12-13T04:01:22.091053Z","shell.execute_reply.started":"2024-12-13T04:01:12.383289Z","shell.execute_reply":"2024-12-13T04:01:22.089823Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Exclude unnecessary columns\ntest_X = test.drop(columns=['id', 'Policy Start Date'], errors='ignore')\n\n# Handle missing values in categorical features by replacing NaN with 'Unknown'\nfor col in test_X.select_dtypes(include=['object']).columns:\n    test_X[col] = test_X[col].fillna('Unknown').astype(str)\n\n# Handle missing values in numerical features by replacing NaN with 0\nfor col in test_X.select_dtypes(include=['float64', 'int64']).columns:\n    test_X[col] = test_X[col].fillna(0)\n\n# Ensure test_X has the same features as the training set\nmissing_cols = set(X_train.columns) - set(test_X.columns)\nfor col in missing_cols:\n    test_X[col] = 0  # Add missing columns with default value 0\ntest_X = test_X[X_train.columns]\n\n# Ensure categorical columns are properly encoded\nfor col in categorical_features:\n    if col in test_X.columns:\n        test_X[col] = test_X[col].astype(str)\n\n# Predict\ntry:\n    premium_predictions = catboost_model.predict(test_X)\nexcept Exception as e:\n    print(f\"Error during prediction: {e}\")\n    raise\n\n# Add predictions to the test dataset\ntest['Predicted_Premium_Amount'] = premium_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T04:01:06.440849Z","iopub.execute_input":"2024-12-13T04:01:06.441889Z","iopub.status.idle":"2024-12-13T04:01:08.334315Z","shell.execute_reply.started":"2024-12-13T04:01:06.441846Z","shell.execute_reply":"2024-12-13T04:01:08.332743Z"}},"outputs":[{"name":"stdout","text":"Error during prediction: There is no trained model to use predict(). Use fit() to train model. Then use this method.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     premium_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mcatboost_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during prediction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/catboost/core.py:5924\u001b[0m, in \u001b[0;36mCatBoostRegressor.predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[0m\n\u001b[1;32m   5922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5923\u001b[0m     prediction_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_default_prediction_type()\n\u001b[0;32m-> 5924\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/catboost/core.py:2620\u001b[0m, in \u001b[0;36mCatBoost._predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[0m\n\u001b[1;32m   2618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2619\u001b[0m     verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 2620\u001b[0m data, data_is_single_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_predict_input_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_method_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2621\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_prediction_type(prediction_type)\n\u001b[1;32m   2623\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_predict(data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/catboost/core.py:2596\u001b[0m, in \u001b[0;36mCatBoost._process_predict_input_data\u001b[0;34m(self, data, parent_method_name, thread_count, label)\u001b[0m\n\u001b[1;32m   2594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_process_predict_input_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, parent_method_name, thread_count, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2595\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fitted() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_count_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2596\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere is no trained model to use \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m(). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2597\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse fit() to train model. Then use this method.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(parent_method_name))\n\u001b[1;32m   2598\u001b[0m     is_single_object \u001b[38;5;241m=\u001b[39m _is_data_single_object(data)\n\u001b[1;32m   2599\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Pool):\n","\u001b[0;31mCatBoostError\u001b[0m: There is no trained model to use predict(). Use fit() to train model. Then use this method."],"ename":"CatBoostError","evalue":"There is no trained model to use predict(). Use fit() to train model. Then use this method.","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"submission=pd.read_csv('/kaggle/input/playground-series-s4e12/sample_submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T04:00:20.704614Z","iopub.execute_input":"2024-12-13T04:00:20.705046Z","iopub.status.idle":"2024-12-13T04:00:20.982873Z","shell.execute_reply.started":"2024-12-13T04:00:20.705009Z","shell.execute_reply":"2024-12-13T04:00:20.981823Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"submission.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T04:00:23.895882Z","iopub.execute_input":"2024-12-13T04:00:23.896326Z","iopub.status.idle":"2024-12-13T04:00:23.913427Z","shell.execute_reply.started":"2024-12-13T04:00:23.896292Z","shell.execute_reply":"2024-12-13T04:00:23.912000Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"        id  Premium Amount\n0  1200000        1102.545\n1  1200001        1102.545\n2  1200002        1102.545\n3  1200003        1102.545\n4  1200004        1102.545","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Premium Amount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1200000</td>\n      <td>1102.545</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1200001</td>\n      <td>1102.545</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1200002</td>\n      <td>1102.545</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1200003</td>\n      <td>1102.545</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1200004</td>\n      <td>1102.545</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"submission['Premium Amount']=premium_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T04:00:27.012595Z","iopub.execute_input":"2024-12-13T04:00:27.013081Z","iopub.status.idle":"2024-12-13T04:00:27.043484Z","shell.execute_reply.started":"2024-12-13T04:00:27.013033Z","shell.execute_reply":"2024-12-13T04:00:27.042016Z"},"jupyter":{"source_hidden":true}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m submission[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPremium Amount\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[43mpremium_predictions\u001b[49m\n","\u001b[0;31mNameError\u001b[0m: name 'premium_predictions' is not defined"],"ename":"NameError","evalue":"name 'premium_predictions' is not defined","output_type":"error"}],"execution_count":12},{"cell_type":"code","source":"submission.to_csv('/kaggle/working/submission.csv',index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T04:00:49.096205Z","iopub.execute_input":"2024-12-13T04:00:49.097401Z","iopub.status.idle":"2024-12-13T04:00:50.228128Z","shell.execute_reply.started":"2024-12-13T04:00:49.097357Z","shell.execute_reply":"2024-12-13T04:00:50.227199Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}